{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do houses in university towns retain more or less value than houses in other regions during a recession?\n",
    "\n",
    "## Background\n",
    "\n",
    "This project is an elaboration on an assignment from the [Introduction to Data Science in Python](https://www.coursera.org/learn/python-data-analysis) class from University of Michigan with Coursera.\n",
    "\n",
    "I will compare mean housing prices in university and non-university towns during a recession. I want to know whether houses in university towns retain more value than houses in non-university towns.\n",
    "\n",
    "**Hypothesis**: Mean housing prices in university towns are less affected by recessions than mean housing prices in other non-university towns. I will calculate a statistic comparing mean price ratios in university and non-university towns to test this hypothesis.\n",
    "\n",
    "Relevant terms:\n",
    "* _quarter_ is a specific three month period; Q1 = Jan-Mar, Q2 = Apr-Jun, Q3 = Jul-Sep, Q4 = Oct-Dec\n",
    "* _recession_ is a period of time; starts with 2 consecutive quarters of GDP decline, ends with 2 consequtive quarters of GDP growth\n",
    "* _recession bottom_ is the quarter in recession with the lowest GDP\n",
    "* _university town_ is a city with a high percentage of university students relative to total population\n",
    "* _price ratio_ is defined as the mean housing price the quarter before a recession starts, divided by the mean housing price during the recession bottom\n",
    "\n",
    "## Methods\n",
    "\n",
    "I will evaluate market loss by comparing mean price ratios; i.e. the value of houses the quarter before a recession starts compared the the value of houses in the recession bottom.\n",
    "\n",
    "I evaluate housing values in the 2008-2009 recession.\n",
    "\n",
    "Housing prices are based on data from zillow. University towns are determined by a list on Wikipedia. Recessions are defined above and identified based on quarterly GDP from the Bureau of Economic Analysis.\n",
    "\n",
    "Datasets:\n",
    "* _Housing prices_ : median home sale prices by region in the United States; ```City_Zhvi_AllHomes.csv``` from [Zillow research data on all homes at a city level](http://files.zillowstatic.com/research/public/City/City_Zhvi_AllHomes.csv)\n",
    "* _University towns_ : list of university towns in the United States; ```university_towns.txt``` from [Wikipedia page on university towns](https://en.wikipedia.org/wiki/List_of_college_towns#College_towns_in_the_United_States)\n",
    "* _GDP_ : GDP in annual and quarterly intervals in the United Statets; ```gdplev.xls``` from [US Dept. of Commerce, Bureau of Economic Analysis GDP over time](http://www.bea.gov/national/index.htm#gdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# set view options to display more rows and columns\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "To compare housing prices in university towns and non-university towns for the quarter before the recession and the recession bottom, we need a clean dataset. That dataset must list a few things.\n",
    "\n",
    "Each record is a city. Columns are whether the town is a unviersity city or not, and its price ratio.\n",
    "\n",
    "To get this information, I need to do a few things:\n",
    "- Identify university towns.\n",
    "- Identify recessions.\n",
    "- Aggregate housing prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify university towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "umich_part_id": "021",
    "umich_partlist_id": "004"
   },
   "outputs": [],
   "source": [
    "# function loads university town dataset and returns dataframe with two columns where \n",
    "# each row represents a university town and the two columns are...\n",
    "# State: unabbreviated state name\n",
    "# RegionName: name of neighborhood or city\n",
    "\n",
    "def identify_university_towns():    \n",
    "    \n",
    "    # read in lines of text from university towns dataset\n",
    "    with open('university_towns.txt') as uni_file:\n",
    "        uni_text = uni_file.read().splitlines()\n",
    "    \n",
    "    # initialize lists of state and region names\n",
    "    state_list = list()\n",
    "    region_list = list()\n",
    "    \n",
    "    # iterate over lines of text\n",
    "    for text in uni_text:\n",
    "        \n",
    "        # is this text a state name?\n",
    "        # if text ends with \"[edit]\", it is a state name\n",
    "        if (text[-6:] == \"[edit]\"):\n",
    "            # save state name without [edit]\n",
    "            state = text[:-6]\n",
    "        \n",
    "        # else this text is a region name\n",
    "        else:\n",
    "            \n",
    "            # look for parenthetical statements in text\n",
    "            i = text.find(\" (\")\n",
    "            \n",
    "            # if there are parenthetical statements\n",
    "            if (i != -1):\n",
    "                # save region name without parenthetical statements\n",
    "                region = text[:i]\n",
    "            \n",
    "            # else there are no parenthetical statements\n",
    "            else:\n",
    "                # save region name as unaltered text\n",
    "                region = text\n",
    "                \n",
    "            # append state and region to lists\n",
    "            state_list.append(state)\n",
    "            region_list.append(region)\n",
    "            \n",
    "    # create data frame from lists\n",
    "    df = pd.DataFrame(list(zip(state_list, region_list)), columns = [\"State\", \"RegionName\"])\n",
    "    \n",
    "    # return data frame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify recessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function loads GDP dataset 2000-2016 and returns dataframe with four columns\n",
    "# where each row representsone recession, and the four columns are...\n",
    "# Before: the quarter before a recession started\n",
    "# Start: the quarter a recession started\n",
    "# Bottom: the recession bottom, the quarter with the lowest GDP within a recession\n",
    "# End: the quarter a recession ended\n",
    "\n",
    "def identify_recession():\n",
    "    # load GDP dataset in billions of chained 2009 dollars\n",
    "    df = pd.read_excel('gdplev.xls', usecols = [4,6], names = ['Quarter', 'GDP'], skiprows = 219)\n",
    "    # each record is the GDP in one quarter\n",
    "    df.set_index('Quarter', inplace = True)\n",
    "    # calculate GDP change between quarters\n",
    "    df['GDP_change'] = df.diff()\n",
    "\n",
    "    # initalize lists to track recession timing\n",
    "    quarter_start_list = []\n",
    "    quarter_before_start_list = []\n",
    "    quarter_bottom_list = []\n",
    "    quarter_end_list = []\n",
    "    \n",
    "    # initialize recession_bottom (will be reset at start of each recession)\n",
    "    recession_bottom = 0\n",
    "\n",
    "    # set recession flag to false\n",
    "    in_recession = False\n",
    "\n",
    "    # iterate through GDP quarter by quarter\n",
    "    for i in np.arange(2, len(df)):\n",
    "\n",
    "        # if we were not in a recession, but GDP decreased this quarter, \n",
    "        # and GDP decreased last quarter, then a recession started last quarter\n",
    "        if ((not in_recession) & (df['GDP_change'].iloc[i] < 0) & (df['GDP_change'].iloc[i-1] < 0)):\n",
    "            # set recession flag to true\n",
    "            in_recession = True\n",
    "            # record quarter when recession starts\n",
    "            quarter_start_list.append(df.iloc[i-1].name)\n",
    "            # record quarter before recession start\n",
    "            quarter_before_start_list.append(df.iloc[i-2].name)\n",
    "            # track quarter of recession bottom\n",
    "            quarter_bottom = df.iloc[i].name\n",
    "            # track recession bottom\n",
    "            recession_bottom = df['GDP'].iloc[i]\n",
    "\n",
    "        # if we are in a recession, and the current GDP is lower than the \n",
    "        # stored recession bottom, update the recesssion bottom\n",
    "        elif (in_recession & (df['GDP_change'].iloc[i] < recession_bottom)):\n",
    "            # update quarter of recession bottom\n",
    "            quarter_bottom = df.iloc[i].name\n",
    "            # update recession bottom\n",
    "            recession_bottom = df['GDP_change'].iloc[i]\n",
    "\n",
    "        # if we were in a recession, but GDP increased this quarter,\n",
    "        # and GDP increased last quarter, then the recession ended this quarter\n",
    "        elif (in_recession & (df['GDP_change'].iloc[i] > 0) & (df['GDP_change'].iloc[i-1] > 0)):\n",
    "            # set recession flag to false\n",
    "            in_recession = False\n",
    "            # record quarter of recession bottom\n",
    "            quarter_bottom_list.append(quarter_bottom)\n",
    "            # record quarter when recession ends\n",
    "            quarter_end_list.append(df.iloc[i].name)\n",
    "\n",
    "    # if we're still in a recession at the end of the dataset\n",
    "    if (in_recession):\n",
    "        # store recession bottom and end as NA\n",
    "        quarter_bottom_list.append(np.NaN)\n",
    "        # record quarter when recession ends\n",
    "        quarter_end_list.append(np.NaN)\n",
    "\n",
    "    # combine lists in to a dataframe, where each column is a list\n",
    "    df = pd.DataFrame([quarter_before_start_list, quarter_start_list,\n",
    "                       quarter_bottom_list, quarter_end_list]).transpose()\n",
    "    # name columns\n",
    "    df.columns = ['Before', 'Start', 'Bottom', 'End']\n",
    "    # return dataframe where each record is one recession\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate housing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function loads housing price dataset for 2000-2016 and returns dataframe with 67 columns  \n",
    "# where each row represents a region and the columns represent mean quarterly housing prices\n",
    "\n",
    "def aggregate_housing_prices():\n",
    "    # read in csv file\n",
    "    df = pd.read_csv('City_Zhvi_AllHomes.csv')\n",
    "    # drop columns before 2000\n",
    "    df.drop(df.iloc[:, 3:51].columns, axis = 1, inplace = True)\n",
    "    # drop region ID column\n",
    "    df.drop(['RegionID'], axis = 1, inplace = True)\n",
    "    # dictionary to map state names to two letter acronyms\n",
    "    states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}\n",
    "    # replace state abbreviations with state names\n",
    "    df.replace({'State': states}, inplace = True)\n",
    "    # set state and region name as multi-level index\n",
    "    df.set_index(['State', 'RegionName'], inplace = True)\n",
    "    # convert column names to date time\n",
    "    df.columns = pd.to_datetime(df.columns)\n",
    "    # average columns across quarters\n",
    "    df = df.resample('Q', axis=1).mean()\n",
    "    # convert column names to string\n",
    "    df.columns = df.columns.to_period(\"Q\").strftime(\"%Yq%q\")\n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.00433226366991648, 'university town')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function loads datasets above, runs a two-sample t-test to compare the mean\n",
    "# price ratio of university and non-university towns during a recession.\n",
    "# output will return three values in a tuple...\n",
    "# 1) True or False: are the mean price ratios statistically significnatly different?\n",
    "# the threshold for statistical significance was arbitrarily chosen as 0.01.\n",
    "# 2) decimal: what's the p-value for t-test?\n",
    "# a lower value indicates that it's less likely the means are the same.\n",
    "# 3) university or non-university: which regions have a lower mean price ratio?\n",
    "# a lower mean price ratio indicates a reduced market loss during a recession,\n",
    "# the houses in these regions retained more value in a recession\n",
    "\n",
    "def run_ttest():\n",
    "    # load recession timing data\n",
    "    recession_data = identify_recession()\n",
    "    # find quarter before recession\n",
    "    quarter_before = recession_data['Before'].iloc[0]\n",
    "    # find quarter of recession bottom\n",
    "    quarter_bottom = recession_data['Bottom'].iloc[0]\n",
    "\n",
    "    # load housing data\n",
    "    housing_data = aggregate_housing_prices()\n",
    "\n",
    "    # calculate price ratio\n",
    "    price_ratio = housing_data[quarter_before] / housing_data[quarter_bottom]\n",
    "    price_ratio.name = 'PriceRatio'\n",
    "\n",
    "    # load university town data\n",
    "    uni_data = identify_university_towns()\n",
    "    # create university column to describe whether a region is a university town\n",
    "    # since this series only includes university towns, every record has a True value\n",
    "    uni_data['University'] = True\n",
    "    # set multi-index of state and region name\n",
    "    uni_data.set_index(['State', 'RegionName'], inplace = True)\n",
    "\n",
    "    # merge price ratio with university towns\n",
    "    df = pd.merge(price_ratio, uni_data, how = 'left', left_index = True, right_index = True)\n",
    "    # set any NaN university values as False\n",
    "    df['University'].replace(np.nan, False, regex = True, inplace = True)\n",
    "\n",
    "    university_price_ratio = df[df['University'] == True]['PriceRatio']\n",
    "    non_university_price_ratio = df[df['University'] == False]['PriceRatio']\n",
    "\n",
    "    test = ttest_ind(university_price_ratio, non_university_price_ratio, nan_policy = 'omit')\n",
    "\n",
    "    # store p-value\n",
    "    p = test.pvalue\n",
    "\n",
    "    # interpret p-value\n",
    "    # if p-value is less than 0.01, then our means are significantly different\n",
    "    # but note that this interpretation is perhaps an overstatement of the meaning\n",
    "    # of a p-value\n",
    "    if (test.pvalue < 0.01):\n",
    "        different = True\n",
    "    else:\n",
    "        different = False\n",
    "\n",
    "    # interpret test statistic\n",
    "    # if t statistic is negative, then the mean of university price ratios\n",
    "    # is lower than the mean of non-university price ratios,\n",
    "    # which represents a reduced market loss in recessions\n",
    "    if (test.statistic < 0):\n",
    "        better = \"university town\"\n",
    "    else:\n",
    "        better = \"non-university town\"\n",
    "\n",
    "    # store interpretations and p-value in tuple\n",
    "    result = (different, p, better)\n",
    "\n",
    "    return result\n",
    "\n",
    "run_ttest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Statistically speaking, my analysis indicates that the mean price ratios are significantly different between university and non-university towns, and that houses in university towns have a reduced market loss relative to houses in non-university towns.\n",
    "\n",
    "Generally speaking, my analysis indicates that houses in university towns retain more market value in a recession than non-university towns. This could indicate that investors should target university areas for less risky investments; if they had to sell on short-notice during a recession, they would lose less money in university areas.\n",
    "\n",
    "That said, this is just one analysis, and there is a 1% chance this relationship was found by random chance and the mean housing prices are the same. Any investment decisions would warrant further research for general market trends and specific investment regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-data-analysis",
   "graded_item_id": "Il9Fx",
   "launcher_item_id": "TeDW0",
   "part_id": "WGlun"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "umich": {
   "id": "Assignment 4",
   "version": "1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
